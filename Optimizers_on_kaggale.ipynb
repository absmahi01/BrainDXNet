{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "WHsHKR41VsO-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import itertools\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.regularizers import l2\n",
        "#Data handling tools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "\n",
        "#Deep learning libs\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D , MaxPooling2D , Flatten , Activation , Dense , Dropout , BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adadelta, Adagrad, Adam, Adamax, Nadam, SGD, RMSprop\n",
        "\n",
        "#Warningds\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSfjlFhTVsPd"
      },
      "outputs": [],
      "source": [
        "train_data_path = \"F:\\\\Mahi\\\\brain mri\\\\kaggaleblurred\\\\train\"\n",
        "\n",
        "filepaths =[]\n",
        "\n",
        "labels = []\n",
        "\n",
        "folds = os.listdir(train_data_path)\n",
        "\n",
        "for fold in folds:\n",
        "    f_path = os.path.join(train_data_path , fold)\n",
        "    filelists = os.listdir(f_path)\n",
        "\n",
        "    for file in filelists:\n",
        "        filepaths.append(os.path.join(f_path , file))\n",
        "        labels.append(fold)\n",
        "\n",
        "#Concat data paths with labels\n",
        "Fseries = pd.Series(filepaths , name = 'filepaths')\n",
        "Lseries = pd.Series(labels , name = 'label')\n",
        "train_df = pd.concat([Fseries , Lseries] , axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq1EoM66VsPh"
      },
      "outputs": [],
      "source": [
        "test_data_path = \"F:\\\\Mahi\\\\brain mri\\\\kaggaleblurred\\\\test\"\n",
        "\n",
        "\n",
        "filepaths =[]\n",
        "labels = []\n",
        "\n",
        "folds = os.listdir(test_data_path)\n",
        "\n",
        "for fold in folds:\n",
        "    f_path = os.path.join(test_data_path , fold)\n",
        "    filelists = os.listdir(f_path)\n",
        "\n",
        "    for file in filelists:\n",
        "        filepaths.append(os.path.join(f_path , file))\n",
        "        labels.append(fold)\n",
        "\n",
        "#Concat data paths with labels\n",
        "Fseries = pd.Series(filepaths , name = 'filepaths')\n",
        "Lseries = pd.Series(labels , name = 'label')\n",
        "test_df = pd.concat([Fseries , Lseries] , axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "img_size = (224 ,224)\n",
        "batch_size = 16\n",
        "\n",
        "ts_gen= ImageDataGenerator()\n",
        "\n",
        "tr_gen= ImageDataGenerator()\n",
        "# Create an instance of the ImageDataGenerator\n",
        "\n",
        "train_gen = tr_gen.flow_from_dataframe(train_df , x_col = 'filepaths' , y_col = 'label' , target_size = img_size ,\n",
        "                                      class_mode = 'categorical' , color_mode = 'rgb' , shuffle = True , batch_size =batch_size)\n",
        "test_gen = ts_gen.flow_from_dataframe(test_df , x_col= 'filepaths' , y_col = 'label' , target_size = img_size, class_mode = 'categorical' ,\n",
        "                                      color_mode= 'rgb', shuffle = False , batch_size = batch_size)"
      ],
      "metadata": {
        "id": "gAlPCt8mkHNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_dict = train_gen.class_indices\n",
        "classes = list(gen_dict.keys())\n",
        "images , labels = next(train_gen)\n",
        "\n",
        "plt.figure(figsize= (20,20))\n",
        "\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    image = images[i] / 255\n",
        "    plt.imshow(image)\n",
        "    index = np.argmax(labels[i])\n",
        "    class_name = classes[index]\n",
        "    plt.title(class_name , color = 'blue' , fontsize= 12)\n",
        "    plt.axis('off')\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "nBKtrcU4kMHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tVqU0IKVsPu"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YQH0oimVsPw"
      },
      "outputs": [],
      "source": [
        "# Specify the path to save the best model weights\n",
        "checkpoint_filepath = 'F:\\\\Mahi\\\\brain mri\\\\cnn7022.h5'\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.0001)\n",
        "# Set up the ModelCheckpoint callback to save weights with the highest validation accuracy\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQbLlw1JVsQU"
      },
      "outputs": [],
      "source": [
        "#Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best so far\n",
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "model2 = Sequential()# contrast change by up to 50%)\n",
        "\n",
        "# Convolutional layer 1\n",
        "model2.add(Conv2D(64, (4, 4), activation=\"relu\", input_shape=(224, 224, 3), padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "#conv2\n",
        "model2.add(Conv2D(64,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "#Convolutional layer 3\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 4\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 5\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        " # Convolutional layer 6\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Full connect layers\n",
        "\n",
        "model2.add(Dense(units= 1024, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=512, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=4, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "history = model2.fit(\n",
        "    x=train_gen,\n",
        "    epochs = 100,\n",
        "    validation_data = test_gen,\n",
        "    steps_per_epoch=119,\n",
        "    callbacks=[reduce_lr, model_checkpoint_callback])\n",
        "#keras.utils.plot_model(model2, to_file='CNN 95.56%_model_architecture.png',show_shapes=True,)"
      ],
      "metadata": {
        "id": "kzCGCf_1ZHkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = model2.predict_generator(test_gen)\n",
        "y_pred = np.argmax(preds , axis = 1)\n",
        "print(classification_report(y_pred,test_gen.classes,digits=6))"
      ],
      "metadata": {
        "id": "f_wXLbzKXNX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy6SFmerVsQe"
      },
      "source": [
        "#\n",
        "Adamax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best so far\n",
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "# Convolutional layer 1\n",
        "model2.add(Conv2D(64, (4, 4), activation=\"relu\", input_shape=(224, 224, 3), padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "#conv2\n",
        "model2.add(Conv2D(64,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "#Convolutional layer 3\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 4\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 5\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        " # Convolutional layer 6\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Full connect layers\n",
        "\n",
        "model2.add(Dense(units= 1024, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=512, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=4, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "history = model2.fit(\n",
        "    x=train_gen,\n",
        "    epochs = 100,\n",
        "    validation_data = test_gen,\n",
        "    steps_per_epoch=119,\n",
        "   # epochs=15,\n",
        "    #validation_data=test_generator,\n",
        "    #validation_steps=69,\n",
        "    callbacks=[reduce_lr, model_checkpoint_callback])\n",
        "#keras.utils.plot_model(model2, to_file='CNN 95.56%_model_architecture.png',show_shapes=True,)"
      ],
      "metadata": {
        "id": "AZZE7Gk-kbE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = model2.predict_generator(test_gen)\n",
        "y_pred = np.argmax(preds , axis = 1)\n",
        "print(classification_report(y_pred,test_gen.classes,digits=6))"
      ],
      "metadata": {
        "id": "orCzocqyke_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8UTUpcRVsQ2"
      },
      "source": [
        "Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best so far\n",
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "# Convolutional layer 1\n",
        "model2.add(Conv2D(64, (4, 4), activation=\"relu\", input_shape=(224, 224, 3), padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "#conv2\n",
        "model2.add(Conv2D(64,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "#Convolutional layer 3\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 4\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 5\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        " # Convolutional layer 6\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Full connect layers\n",
        "\n",
        "model2.add(Dense(units= 1024, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=512, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=4, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(optimizer=Adadelta(learning_rate=0.001), loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "history = model2.fit(\n",
        "    x=train_gen,\n",
        "    epochs = 100,\n",
        "    validation_data = test_gen,\n",
        "    steps_per_epoch=119,\n",
        "   # epochs=15,\n",
        "    #validation_data=test_generator,\n",
        "    #validation_steps=69,\n",
        "    callbacks=[reduce_lr, model_checkpoint_callback])\n",
        "#keras.utils.plot_model(model2, to_file='CNN 95.56%_model_architecture.png',show_shapes=True,)"
      ],
      "metadata": {
        "id": "LVHIOW03X4CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = model2.predict_generator(test_gen)\n",
        "y_pred = np.argmax(preds , axis = 1)\n",
        "print(classification_report(y_pred,test_gen.classes,digits=6))"
      ],
      "metadata": {
        "id": "d8PbGwemX97I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn_C1iFXVsQ9"
      },
      "source": [
        "Adagrad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best so far\n",
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "model2 = Sequential()# contrast change by up to 50%)\n",
        "\n",
        "# Convolutional layer 1\n",
        "model2.add(Conv2D(64, (4, 4), activation=\"relu\", input_shape=(224, 224, 3), padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "#conv2\n",
        "model2.add(Conv2D(64,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "#Convolutional layer 3\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 4\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 5\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        " # Convolutional layer 6\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Full connect layers\n",
        "\n",
        "model2.add(Dense(units= 1024, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=512, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=4, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(optimizer=Adagrad(learning_rate=0.001), loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "history = model2.fit(\n",
        "    x=train_gen,\n",
        "    epochs = 100,\n",
        "    validation_data = test_gen,\n",
        "    steps_per_epoch=119,\n",
        "   # epochs=15,\n",
        "    #validation_data=test_generator,\n",
        "    #validation_steps=69,\n",
        "    callbacks=[reduce_lr, model_checkpoint_callback])\n",
        "#keras.utils.plot_model(model2, to_file='CNN 95.56%_model_architecture.png',show_shapes=True,)"
      ],
      "metadata": {
        "id": "6sp5bSK9YDXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = model2.predict_generator(test_gen)\n",
        "y_pred = np.argmax(preds , axis = 1)\n",
        "print(classification_report(y_pred,test_gen.classes,digits=6))"
      ],
      "metadata": {
        "id": "Lx_PcSGAYH5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_sHR4GRVsRD"
      },
      "source": [
        "Nadam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best so far\n",
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "model2 = Sequential()# contrast change by up to 50%)\n",
        "\n",
        "# Convolutional layer 1\n",
        "model2.add(Conv2D(64, (4, 4), activation=\"relu\", input_shape=(224, 224, 3), padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "#conv2\n",
        "model2.add(Conv2D(64,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "#Convolutional layer 3\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 4\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 5\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        " # Convolutional layer 6\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Full connect layers\n",
        "\n",
        "model2.add(Dense(units= 1024, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=512, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=4, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(optimizer=Nadam(learning_rate=0.001), loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "history = model2.fit(\n",
        "    x=train_gen,\n",
        "    epochs = 100,\n",
        "    validation_data = test_gen,\n",
        "    steps_per_epoch=119,\n",
        "   # epochs=15,\n",
        "    #validation_data=test_generator,\n",
        "    #validation_steps=69,\n",
        "    callbacks=[reduce_lr, model_checkpoint_callback])\n",
        "#keras.utils.plot_model(model2, to_file='CNN 95.56%_model_architecture.png',show_shapes=True,)"
      ],
      "metadata": {
        "id": "HZgB2393YNbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = model2.predict_generator(test_gen)\n",
        "y_pred = np.argmax(preds , axis = 1)\n",
        "print(classification_report(y_pred,test_gen.classes,digits=6))"
      ],
      "metadata": {
        "id": "uG5jy1ouYV2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi9jtzLvVsRm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIIH7AdFVsRo"
      },
      "source": [
        "SGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best so far\n",
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "model2 = Sequential()# contrast change by up to 50%)\n",
        "\n",
        "# Convolutional layer 1\n",
        "model2.add(Conv2D(64, (4, 4), activation=\"relu\", input_shape=(224, 224, 3), padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "#conv2\n",
        "model2.add(Conv2D(64,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "#Convolutional layer 3\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 4\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 5\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        " # Convolutional layer 6\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Full connect layers\n",
        "\n",
        "model2.add(Dense(units= 1024, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=512, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=4, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "history = model2.fit(\n",
        "    x=train_gen,\n",
        "    epochs = 100,\n",
        "    validation_data = test_gen,\n",
        "    steps_per_epoch=119,\n",
        "   # epochs=15,\n",
        "    #validation_data=test_generator,\n",
        "    #validation_steps=69,\n",
        "    callbacks=[reduce_lr, model_checkpoint_callback])\n",
        "#keras.utils.plot_model(model2, to_file='CNN 95.56%_model_architecture.png',show_shapes=True,)"
      ],
      "metadata": {
        "id": "KL6vMaVNYcz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = model2.predict_generator(test_gen)\n",
        "y_pred = np.argmax(preds , axis = 1)\n",
        "print(classification_report(y_pred,test_gen.classes,digits=6))"
      ],
      "metadata": {
        "id": "YJT61ZuJYhnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mFSk4V3VsRv"
      },
      "source": [
        "RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best so far\n",
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "model2 = Sequential()# contrast change by up to 50%)\n",
        "\n",
        "# Convolutional layer 1\n",
        "model2.add(Conv2D(64, (4, 4), activation=\"relu\", input_shape=(224, 224, 3), padding='same'))\n",
        "model2.add(MaxPooling2D(pool_size=(3, 3), padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "#conv2\n",
        "model2.add(Conv2D(64,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "#Convolutional layer 3\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 4\n",
        "model2.add(Conv2D(128,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "# Convolutional layer 5\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        " # Convolutional layer 6\n",
        "model2.add(Conv2D(256,(4,4), padding='same', activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Full connect layers\n",
        "\n",
        "model2.add(Dense(units= 1024, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=512, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(units=4, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "history = model2.fit(\n",
        "    x=train_gen,\n",
        "    epochs = 100,\n",
        "    validation_data = test_gen,\n",
        "    steps_per_epoch=119,\n",
        "   # epochs=15,\n",
        "    #validation_data=test_generator,\n",
        "    #validation_steps=69,\n",
        "    callbacks=[reduce_lr, model_checkpoint_callback])\n",
        "#keras.utils.plot_model(model2, to_file='CNN 95.56%_model_architecture.png',show_shapes=True,)"
      ],
      "metadata": {
        "id": "tiF769ilYnYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preds = model2.predict_generator(test_gen)\n",
        "y_pred = np.argmax(preds , axis = 1)\n",
        "print(classification_report(y_pred,test_gen.classes,digits=6))"
      ],
      "metadata": {
        "id": "kbwqJv5WYr7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBe_mwdPVsSm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52jsy4WdVsSv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiCkGgEnVsSy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4382864,
          "sourceId": 7524093,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30648,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}